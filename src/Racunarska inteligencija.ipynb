{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd               # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np                # linear algebra\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from sklearn import datasets \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import losses, optimizers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    \n",
    "    def __init__(self, weights, velocity, omega, c1, c2, \n",
    "                 lower_bound, upper_bound, particle_id):\n",
    "        self.id = particle_id\n",
    "        self.weights = weights\n",
    "        self.best_weights = weights\n",
    "        self.velocity = np.array(velocity)\n",
    "        self.omega = omega\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.lower_bound = lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "        self.best_valuation = 0\n",
    "        self.history = []\n",
    "        \n",
    "    def update(self, best_particle):\n",
    "        self.update_velocity(best_particle)\n",
    "        self.check_velocity()\n",
    "        self.update_particle()\n",
    "        # self.check_weights()\n",
    "        \n",
    "        return self.weights\n",
    "    \n",
    "    def update_velocity(self, bp):\n",
    "        # v = Wv + c1r1(pi - xi) + c2r2(g - xi)\n",
    "        # v        - ubrzanje \n",
    "        # W        - omega \n",
    "        # c1 i c2  - unapred zadati parametri\n",
    "        # r1 i r2  - slucajni brojevi iz (0,1) uniformne raspodele\n",
    "        # pi       - najbolje resenje trenutne jedinke\n",
    "        # g        - najbojle globalno resenje\n",
    "        r1 = np.random.random()\n",
    "        r2 = np.random.random()\n",
    "        \n",
    "        self.velocity = self.omega * self.velocity + self.c1*r1*(np.add(np.array(self.best_weights), (-1)*np.array(self.weights))) + self.c2*r2*(np.add(np.array(bp), (-1)*np.array(self.weights))) \n",
    "        \n",
    "    def check_velocity(self):\n",
    "        for i in range(len(self.velocity)):\n",
    "            if(i%2 == 1):\n",
    "                for j in range(len(self.velocity[i])): \n",
    "                    if(self.velocity[i][j] < self.lower_bound):\n",
    "                        self.velocity[i][j] = self.lower_bound\n",
    "                    \n",
    "                    if(self.velocity[i][j] > self.upper_bound): \n",
    "                        self.velocity[i][j] = self.upper_bound\n",
    "            else: \n",
    "                for j in range(len(self.velocity[i])):\n",
    "                    for k in range(len(self.velocity[i][j])):\n",
    "            \n",
    "                        if(self.velocity[i][j][k] < self.lower_bound):\n",
    "                            self.velocity[i][j][k] = self.lower_bound\n",
    "                \n",
    "                        if(self.velocity[i][j][k] > self.upper_bound): \n",
    "                            self.velocity[i][j][k] = self.upper_bound\n",
    "        \n",
    "        return \n",
    "    \n",
    "    \n",
    "    def update_particle(self):\n",
    "        # xi = xi + vi\n",
    "        self.weights = np.add(np.array(self.weights), self.velocity)\n",
    "        \n",
    "    def update_valuation(self, valuation):\n",
    "        self.history.append(valuation)\n",
    "        \n",
    "        if(valuation > self.best_valuation):\n",
    "            self.best_valuation = valuation\n",
    "            self.best_weights = self.weights\n",
    "            \n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "    \n",
    "    def set_weights(self, new_weights):\n",
    "        self.weights = new_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PSO:\n",
    "    def __init__(self, num_particles, num_iters, training_x, training_y, model, shapes, c1, c2, w, lower_bound, upper_bound):\n",
    "        self.num_iters = num_iters\n",
    "        self.training_x = training_x\n",
    "        self.training_y = training_y\n",
    "        self.model = model\n",
    "        self.best_particle = self.make_velocity(shapes)\n",
    "        self.best_evaluation = 0\n",
    "        self.history = []\n",
    "        self.shapes = shapes\n",
    "        self.lower_bound = lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "        self.particles = self.make_particles(num_particles, shapes, c1, c2, w, lower_bound, upper_bound)\n",
    "        self.evaluate_particles()\n",
    "        self.combo = 0\n",
    "        self.w = w\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        \n",
    "        \n",
    "    def make_particles(self, size, shape, c1, c2, w, low, upp):\n",
    "        particles = []\n",
    "        \n",
    "        velocity = self.make_velocity(shape)\n",
    "        \n",
    "        for i in range(size):\n",
    "            weights = self.make_weights(shape, low, upp)\n",
    "            particles.append(Particle(weights, velocity, w, c1, c2, low, upp, i))\n",
    "            \n",
    "        return particles\n",
    "    \n",
    "    def make_velocity(self, shapes):\n",
    "        velocity = []\n",
    "        \n",
    "        for shape in shapes:\n",
    "            velocity.append(np.zeros(shape))\n",
    "        \n",
    "        return velocity\n",
    "                \n",
    "        \n",
    "    def make_weights(self, shapes, low, upp):\n",
    "        weights = []\n",
    "        \n",
    "        for shape in shapes:\n",
    "            if(len(shape) == 1):\n",
    "                # wght da dobijemo vrednosti iz (0, upp-low)\n",
    "                wght = rand(shape[0])*(upp-low)\n",
    "                rec = np.full(shape, low)\n",
    "                \n",
    "                weights.append(np.add(wght, rec))\n",
    "                \n",
    "            else:\n",
    "                wght = rand(shape[0], shape[1])*(upp-low)\n",
    "                rec = np.full(shape, low)\n",
    "                \n",
    "                weights.append(np.add(wght, rec))\n",
    "                \n",
    "        return weights\n",
    "        \n",
    "        \n",
    "    def evaluate_particles(self):\n",
    "        \n",
    "        for particle in self.particles:\n",
    "            self.model.set_weights(particle.get_weights())\n",
    "            train_loss, train_acc = self.model.evaluate(self.training_x, self.training_y, verbose = 0)\n",
    "            \n",
    "            particle.update_valuation(train_acc)\n",
    "            \n",
    "            if(train_acc > self.best_evaluation):\n",
    "                self.best_particle = particle.get_weights()\n",
    "                self.best_evaluation = train_acc\n",
    "        \n",
    "        \n",
    "    def isclose(self, a, b, rel_tol=1e-09, abs_tol=0.0):\n",
    "        return abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol)\n",
    "    \n",
    "    def update_particles(self):\n",
    "        \n",
    "        for particle in self.particles:\n",
    "            particle.update(self.best_particle)\n",
    "            \n",
    "    def get_particles(self):\n",
    "        return self.particles\n",
    "    \n",
    "    def start_pso(self):\n",
    "        \n",
    "        for i in range(self.num_iters):\n",
    "            partly_best_solution = self.best_evaluation\n",
    "            self.update_particles()\n",
    "            self.evaluate_particles()\n",
    "            \n",
    "            #print(\"Iteracija: {}\\nPreciznost: {}\\n\".format(i+1, self.best_evaluation))\n",
    "            \n",
    "            if(self.isclose(partly_best_solution, self.best_evaluation, 0.001)):\n",
    "                self.combo += 1\n",
    "            else:\n",
    "                self.combo = 0\n",
    "                \n",
    "            if(self.combo == 5):\n",
    "                self.particles.sort(key = lambda x: x.best_valuation)\n",
    "                \n",
    "                velocity = self.make_velocity(self.shapes)\n",
    "                \n",
    "                weights = self.make_weights(self.shapes, self.lower_bound, self.upper_bound)\n",
    "                self.particles[0] = Particle(weights, velocity, self.w, self.c1, self.c2, \n",
    "                                             self.lower_bound, self.upper_bound, self.particles[0].id)\n",
    "                \n",
    "                weights = self.make_weights(self.shapes, self.lower_bound, self.upper_bound)\n",
    "                self.particles[1] = Particle(weights, velocity, self.w, self.c1, self.c2, \n",
    "                                             self.lower_bound, self.upper_bound, self.particles[1].id)\n",
    "                \n",
    "                weights = self.make_weights(self.shapes, self.lower_bound, self.upper_bound)\n",
    "                self.particles[2] = Particle(weights, velocity, self.w, self.c1, self.c2, \n",
    "                                             self.lower_bound, self.upper_bound, self.particles[2].id)\n",
    "                \n",
    "                weights = self.make_weights(self.shapes, self.lower_bound, self.upper_bound)\n",
    "                self.particles[3] = Particle(weights, velocity, self.w, self.c1, self.c2, \n",
    "                                             self.lower_bound, self.upper_bound, self.particles[3].id)\n",
    "                \n",
    "                weights = self.make_weights(self.shapes, self.lower_bound, self.upper_bound)\n",
    "                self.particles[4] = Particle(weights, velocity, self.w, self.c1, self.c2, \n",
    "                                             self.lower_bound, self.upper_bound, self.particles[4].id)\n",
    "                self.combo = 0\n",
    "                self.evaluate_particles()\n",
    "                #print(\"Change bad particles\")\n",
    "            \n",
    "            self.history.append(self.best_evaluation)   \n",
    "                \n",
    "                \n",
    "            \n",
    "        return self.best_particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS DATASET: \n",
      "\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 100)               500       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 803\n",
      "Trainable params: 803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 0s 117us/step\n",
      "50/50 [==============================] - 0s 87us/step\n",
      "Current PSO train accuracy: 0.9700000286102295\n",
      "Current PSO test accuracy:   0.9599999785423279\n",
      "\n",
      "100/100 [==============================] - 0s 81us/step\n",
      "50/50 [==============================] - 0s 171us/step\n",
      "Current PSO train accuracy: 0.6899999976158142\n",
      "Current PSO test accuracy:   0.6200000047683716\n",
      "\n",
      "100/100 [==============================] - 0s 84us/step\n",
      "50/50 [==============================] - 0s 116us/step\n",
      "Current PSO train accuracy: 0.949999988079071\n",
      "Current PSO test accuracy:   0.9200000166893005\n",
      "\n",
      "100/100 [==============================] - 0s 93us/step\n",
      "50/50 [==============================] - 0s 123us/step\n",
      "Current PSO train accuracy: 0.6899999976158142\n",
      "Current PSO test accuracy:   0.6200000047683716\n",
      "\n",
      "100/100 [==============================] - 0s 93us/step\n",
      "50/50 [==============================] - 0s 117us/step\n",
      "Current PSO train accuracy: 0.9300000071525574\n",
      "Current PSO test accuracy:   0.8600000143051147\n",
      "\n",
      "\n",
      "Global best accuracy: 0.9599999785423279\n",
      "\n",
      "---------------------------------\n",
      "BREAST CANCER DATASET: \n",
      "\n",
      "\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 100)               3100      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 3,302\n",
      "Trainable params: 3,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "381/381 [==============================] - 0s 47us/step\n",
      "188/188 [==============================] - 0s 60us/step\n",
      "Current PSO train accuracy: 0.9238845109939575\n",
      "Current PSO test accuracy:   0.9095744490623474\n",
      "\n",
      "381/381 [==============================] - 0s 49us/step\n",
      "188/188 [==============================] - 0s 58us/step\n",
      "Current PSO train accuracy: 0.9238845109939575\n",
      "Current PSO test accuracy:   0.8776595592498779\n",
      "\n",
      "381/381 [==============================] - 0s 49us/step\n",
      "188/188 [==============================] - 0s 57us/step\n",
      "Current PSO train accuracy: 0.9160104990005493\n",
      "Current PSO test accuracy:   0.9042553305625916\n",
      "\n",
      "381/381 [==============================] - 0s 60us/step\n",
      "188/188 [==============================] - 0s 67us/step\n",
      "Current PSO train accuracy: 0.9370078444480896\n",
      "Current PSO test accuracy:   0.8936170339584351\n",
      "\n",
      "381/381 [==============================] - 0s 52us/step\n",
      "188/188 [==============================] - 0s 53us/step\n",
      "Current PSO train accuracy: 0.9291338324546814\n",
      "Current PSO test accuracy:   0.914893627166748\n",
      "\n",
      "\n",
      "Global best accuracy: 0.914893627166748\n",
      "\n",
      "---------------------------------\n",
      "WINE DATASET: \n",
      "\n",
      "\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 100)               1400      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 1,703\n",
      "Trainable params: 1,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "119/119 [==============================] - 0s 70us/step\n",
      "59/59 [==============================] - 0s 179us/step\n",
      "Current PSO train accuracy: 0.7142857313156128\n",
      "Current PSO test accuracy:   0.6779661178588867\n",
      "\n",
      "119/119 [==============================] - 0s 73us/step\n",
      "59/59 [==============================] - 0s 101us/step\n",
      "Current PSO train accuracy: 0.6890756487846375\n",
      "Current PSO test accuracy:   0.6610169410705566\n",
      "\n",
      "119/119 [==============================] - 0s 59us/step\n",
      "59/59 [==============================] - 0s 111us/step\n",
      "Current PSO train accuracy: 0.7142857313156128\n",
      "Current PSO test accuracy:   0.6610169410705566\n",
      "\n",
      "119/119 [==============================] - 0s 67us/step\n",
      "59/59 [==============================] - 0s 98us/step\n",
      "Current PSO train accuracy: 0.6890756487846375\n",
      "Current PSO test accuracy:   0.6610169410705566\n",
      "\n",
      "119/119 [==============================] - 0s 53us/step\n",
      "59/59 [==============================] - 0s 84us/step\n",
      "Current PSO train accuracy: 0.6890756487846375\n",
      "Current PSO test accuracy:   0.6610169410705566\n",
      "\n",
      "\n",
      "Global best accuracy: 0.6779661178588867\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "print(\"IRIS DATASET: \\n\\n\")\n",
    "data1 = datasets.load_iris()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data1.data, \n",
    "                                                    data1.target, \n",
    "                                                    test_size=0.33)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "\n",
    "# Pravljenje neuronske mreze sa 3 sloja - ulazni, skriveni i izlazni\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(units=y_train.shape[1], activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "shapes = [i.shape for i in model.get_weights()]\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "            loss=losses.categorical_crossentropy, \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "best_test_acc = 0\n",
    "best_pso = None\n",
    "\n",
    "PSOS = []\n",
    "for i in range(5):\n",
    "    pso = PSO(30, 300, \n",
    "            x_train, y_train, \n",
    "            model, \n",
    "            shapes, \n",
    "            0.5, 1.0, 0.3, -2, 2)\n",
    "\n",
    "    PSOS.append(pso)\n",
    "\n",
    "for pso in PSOS:\n",
    "\n",
    "    best_particle = pso.start_pso()\n",
    "\n",
    "    model.set_weights(best_particle)\n",
    "\n",
    "    train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "    if(best_test_acc < test_acc): \n",
    "        best_test_acc = test_acc\n",
    "        best_pso = pso\n",
    "\n",
    "    print(\"Current PSO train accuracy: \" + str(train_acc))\n",
    "    print(\"Current PSO test accuracy:   \" + str(test_acc) + \"\\n\")\n",
    "\n",
    "print()\n",
    "print(\"Global best accuracy: \" + str(best_test_acc))\n",
    "accs.append(best_test_acc)\n",
    "\n",
    "\n",
    "########################################################################\n",
    "print(\"\\n---------------------------------\\nBREAST CANCER DATASET: \\n\\n\")\n",
    "data2 = datasets.load_breast_cancer()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data2.data, \n",
    "                                                    data2.target, \n",
    "                                                    test_size=0.33)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Pravljenje neuronske mreze sa 3 sloja - ulazni, skriveni i izlazni\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(units=y_train.shape[1], activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "shapes = [i.shape for i in model.get_weights()]\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "            loss=losses.categorical_crossentropy, \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "best_test_acc = 0\n",
    "best_pso = None\n",
    "\n",
    "PSOS = []\n",
    "for i in range(5):\n",
    "    pso = PSO(30, 300, \n",
    "            x_train, y_train, \n",
    "            model, \n",
    "            shapes, \n",
    "            0.5, 1.0, 0.3, -2, 2)\n",
    "\n",
    "    PSOS.append(pso)\n",
    "\n",
    "for pso in PSOS:\n",
    "\n",
    "    best_particle = pso.start_pso()\n",
    "\n",
    "    model.set_weights(best_particle)\n",
    "\n",
    "    train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "    if(best_test_acc < test_acc): \n",
    "        best_test_acc = test_acc\n",
    "        best_pso = pso\n",
    "\n",
    "    print(\"Current PSO train accuracy: \" + str(train_acc))\n",
    "    print(\"Current PSO test accuracy:   \" + str(test_acc) + \"\\n\")\n",
    "\n",
    "print()\n",
    "print(\"Global best accuracy: \" + str(best_test_acc))\n",
    "accs.append(best_test_acc)\n",
    "\n",
    "#######################################################################\n",
    "print(\"\\n---------------------------------\\nWINE DATASET: \\n\\n\")\n",
    "data3 = datasets.load_wine()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data3.data, \n",
    "                                                    data3.target, \n",
    "                                                    test_size=0.33)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Pravljenje neuronske mreze sa 3 sloja - ulazni, skriveni i izlazni\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(units=y_train.shape[1], activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "shapes = [i.shape for i in model.get_weights()]\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "            loss=losses.categorical_crossentropy, \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "best_test_acc = 0\n",
    "best_pso = None\n",
    "\n",
    "PSOS = []\n",
    "for i in range(5):\n",
    "    pso = PSO(30, 300, \n",
    "            x_train, y_train, \n",
    "            model, \n",
    "            shapes, \n",
    "            0.5, 1.0, 0.3, -2, 2)\n",
    "\n",
    "    PSOS.append(pso)\n",
    "\n",
    "for pso in PSOS:\n",
    "\n",
    "    best_particle = pso.start_pso()\n",
    "\n",
    "    model.set_weights(best_particle)\n",
    "\n",
    "    train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "    if(best_test_acc < test_acc): \n",
    "        best_test_acc = test_acc\n",
    "        best_pso = pso\n",
    "\n",
    "    print(\"Current PSO train accuracy: \" + str(train_acc))\n",
    "    print(\"Current PSO test accuracy:   \" + str(test_acc) + \"\\n\")\n",
    "\n",
    "print()\n",
    "print(\"Global best accuracy: \" + str(best_test_acc))\n",
    "accs.append(best_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3499999940395355\n",
      "0.3499999940395355\n",
      "0.3499999940395355\n",
      "0.6200000047683716\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.6899999976158142\n",
      "0.8399999737739563\n",
      "0.8399999737739563\n",
      "0.8399999737739563\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8500000238418579\n",
      "0.8799999952316284\n",
      "0.8799999952316284\n",
      "0.8999999761581421\n",
      "0.8999999761581421\n",
      "0.8999999761581421\n",
      "0.8999999761581421\n",
      "0.8999999761581421\n",
      "0.8999999761581421\n",
      "0.8999999761581421\n",
      "0.8999999761581421\n",
      "0.8999999761581421\n",
      "0.8999999761581421\n",
      "0.9200000166893005\n",
      "0.9300000071525574\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.9399999976158142\n",
      "0.949999988079071\n",
      "0.949999988079071\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n",
      "0.9599999785423279\n"
     ]
    }
   ],
   "source": [
    "for x in best_pso.history:\n",
    "    print(x)\n",
    "    # history moze da nam sluzi za grafik napredovanja algoritma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGzCAYAAADT4Tb9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de1RVZeL/8c8B4QApqIGghEGmJXlBcWlUiE4omjqplWYlhlpZOplMN1PByzcxS7KLZTe1i42mld++aTZIg1pqJl66WHlPJwU0FRBTjLN/f8zPMx0BRUQOPL5fa5214jnP3vs5cBzfs/c+aLMsyxIAAIAhPNy9AAAAgKpE3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDeAwWw2W4UeWVlZF3ys48ePa+LEiVWyLwC4EHXcvQAAF8+7777r8vU777yjjIyMUuMtW7a84GMdP35ckyZNkiR16dLlgvcHAJVF3AAGu+eee1y+XrdunTIyMkqN49yKiop02WWXuXsZACqAy1LAJc7hcGjmzJm67rrr5OPjo+DgYD3wwAM6cuSIy7wNGzYoISFBgYGB8vX1VUREhIYOHSpJ2rNnj4KCgiRJkyZNcl7umjhxYrnHPXz4sB599FG1bt1adevWlb+/v3r27KktW7aUmnvixAlNnDhRLVq0kI+Pjxo3bqz+/ftr586dLq/jhRdeUOvWreXj46OgoCD16NFDGzZscK7RZrNp3rx5pfZ/5lonTpwom82mrVu36q677lKDBg100003SZK+/fZb3Xvvvbrqqqvk4+OjkJAQDR06VL/99pvLPk/vY8eOHbr33ntVv359BQQEKCkpScePHy+1hvfee08dO3aUn5+fGjRooM6dO+uf//ynJGnIkCEKDAzUqVOnSm3XvXt3XXPNNeV+n4FLEWdugEvcAw88oHnz5ikpKUkPP/ywdu/erZdfflmbNm3SV199JS8vL+Xl5al79+4KCgrSk08+qfr162vPnj366KOPJElBQUF69dVX9eCDD6pfv37q37+/JKlNmzblHnfXrl1asmSJ7rjjDkVERCg3N1evvfaa4uLitHXrVjVp0kSSVFJSot69eyszM1N33nmnRo8ercLCQmVkZOj7779Xs2bNJEnDhg3TvHnz1LNnTw0fPlx//PGHVq9erXXr1qlDhw6V+t7ccccdat68uaZOnSrLsiRJGRkZ2rVrl5KSkhQSEqIffvhBr7/+un744QetW7dONpvNZR8DBgxQRESE0tLStHHjRr355ptq1KiRnnnmGeecSZMmaeLEibrhhhs0efJkeXt76+uvv9YXX3yh7t27a/DgwXrnnXf0+eefq3fv3s7tcnJy9MUXXyg1NbVSrw8wlgXgkjFy5Ejrz3/sV69ebUmy5s+f7zJv+fLlLuMff/yxJcn65ptvyt33wYMHLUlWampqhdZy4sQJq6SkxGVs9+7dlt1utyZPnuwcmzNnjiXJSk9PL7UPh8NhWZZlffHFF5Yk6+GHHy53zu7duy1J1ty5c0vNOXPdqampliRr0KBBpeYeP3681Ng//vEPS5K1atWqUvsYOnSoy9x+/fpZl19+ufPr7du3Wx4eHla/fv1KfT9Or72kpMS64oorrIEDB7o8n56ebtlsNmvXrl2l1gRcyrgsBVzCFi1apICAAHXr1k2HDh1yPqKjo1W3bl3961//kiTVr19fkvTpp5+WeWmkMux2uzw8/vM/QSUlJfrtt99Ut25dXXPNNdq4caNz3ocffqjAwED97W9/K7WP02dJPvzwQ9lstjLPYJx5JuV8jBgxotSYr6+v879PnDihQ4cO6frrr5ckl3WXt4/Y2Fj99ttvKigokCQtWbJEDodDKSkpzu/HmWv38PDQ3XffrU8++USFhYXO5+fPn68bbrhBERERlXyFgJmIG+AStn37duXn56tRo0YKCgpyeRw7dkx5eXmSpLi4ON12222aNGmSAgMDdeutt2ru3Lk6efJkpY/tcDj0/PPPq3nz5rLb7QoMDFRQUJC+/fZb5efnO+ft3LlT11xzjerUKf8q+s6dO9WkSRM1bNiw0uspS1nRcPjwYY0ePVrBwcHy9fVVUFCQc96f131a06ZNXb5u0KCBJDnvadq5c6c8PDwUGRl51rUkJibq999/18cffyxJ+vnnn5Wdna3Bgwef/wsDDMc9N8AlzOFwqFGjRpo/f36Zz5++Sdhms2nx4sVat26d/u///k+ff/65hg4dqhkzZmjdunWqW7fueR976tSpmjBhgoYOHaopU6aoYcOG8vDw0COPPCKHw3FBr6ss5Z3BKSkpKXebP5+lOW3AgAFas2aNHnvsMUVFRalu3bpyOBzq0aNHmev29PQsc9/W/7+Hp6IiIyMVHR2t9957T4mJiXrvvffk7e2tAQMGnNd+gEsBcQNcwpo1a6YVK1boxhtvLPMv8jNdf/31uv766/X000/r/fff1913360FCxZo+PDh5335Z/Hixerataveeustl/GjR48qMDDQZY1ff/21Tp06JS8vr3Jfx+eff67Dhw+Xe/bm9BmTo0ePuoz/8ssvFV7zkSNHlJmZqUmTJiklJcU5vn379grv40zNmjWTw+HQ1q1bFRUVdda5iYmJSk5O1oEDB/T++++rV69eztcF4L+4LAVcwgYMGKCSkhJNmTKl1HN//PGHMwSOHDlS6kzD6b+IT1+a8vPzk1Q6Hsrj6elZap+LFi3Sr7/+6jJ222236dChQ3r55ZdL7eP09rfddpssy3L+EsGy5vj7+yswMFCrVq1yef6VV16p0HpPr/nP+zxt5syZFd7Hmfr27SsPDw9Nnjy51JmfM48zaNAg2Ww2jR49Wrt27eL3FQHl4MwNcAmLi4vTAw88oLS0NG3evFndu3eXl5eXtm/frkWLFumFF17Q7bffrrfffluvvPKK+vXrp2bNmqmwsFBvvPGG/P39dcstt0j6zyWcyMhILVy4UC1atFDDhg3VqlUrtWrVqsxj9+7dW5MnT1ZSUpJuuOEGfffdd5o/f76uuuoql3mJiYl65513lJycrPXr1ys2NlZFRUVasWKFHnroId16663q2rWrBg8erBdffFHbt293XiJavXq1unbtqlGjRkmShg8frmnTpmn48OHq0KGDVq1apW3btlX4++Xv76/OnTtr+vTpOnXqlEJDQ/XPf/5Tu3fvruRPQLr66qs1btw4TZkyRbGxserfv7/sdru++eYbNWnSRGlpac65p393z6JFi1S/fn316tWr0scFjOa+D2oBqG5nfhT8tNdff92Kjo62fH19rXr16lmtW7e2Hn/8cWv//v2WZVnWxo0brUGDBllNmza17Ha71ahRI6t3797Whg0bXPazZs0aKzo62vL29j7nx8JPnDhh/f3vf7caN25s+fr6WjfeeKO1du1aKy4uzoqLi3OZe/z4cWvcuHFWRESE5eXlZYWEhFi33367tXPnTuecP/74w3r22Weta6+91vL29raCgoKsnj17WtnZ2S77GTZsmBUQEGDVq1fPGjBggJWXl1fuR8EPHjxYat3//ve/rX79+ln169e3AgICrDvuuMPav39/hfcxd+5cS5K1e/dul/E5c+ZY7dq1s+x2u9WgQQMrLi7OysjIKHX8Dz74wJJk3X///eV+b4FLnc2yzvOuNgCA2/zv//6v+vbtq1WrVik2NtbdywFqJOIGAGqR3r1768cff9SOHTsu6Hf4ACbjnhsAqAUWLFigb7/9VkuXLtULL7xA2ABnwZkbAKgFbDab6tatq4EDB2r27Nln/aWGwKWOPx0AUAvw/0OBiuP33AAAAKMQNwAAwChuvSy1atUqPfvss8rOztaBAwf08ccfq2/fvmfdJisrS8nJyfrhhx8UFham8ePH6957763wMR0Oh/bv36969epxQx4AALWEZVkqLCxUkyZN5OFx9nMzbo2boqIitW3bVkOHDlX//v3POX/37t3q1auXRowYofnz5yszM1PDhw9X48aNlZCQUKFj7t+/X2FhYRe6dAAA4Ab79u3TFVdccdY5NebTUjab7Zxnbp544gktXbpU33//vXPszjvv1NGjR7V8+fIytzl58qTz376RpPz8fDVt2lT79u2Tv79/1b0AAABw0RQUFCgsLExHjx5VQEDAWefWqk9LrV27VvHx8S5jCQkJeuSRR8rdJi0trcx/TM/f35+4AQCglqnILSW16obinJwcBQcHu4wFBweroKBAv//+e5nbjB07Vvn5+c7Hvn37qmOpAADATWrVmZvKsNvtstvt7l4GAACoJrXqzE1ISIhyc3NdxnJzc+Xv7y9fX183rQoAANQktSpuYmJilJmZ6TKWkZGhmJgYN60IAADUNG6Nm2PHjmnz5s3avHmzpP981Hvz5s3au3evpP/cL5OYmOicP2LECO3atUuPP/64fvrpJ73yyiv64IMPNGbMGLesHwAA1DxujZsNGzaoXbt2ateunSQpOTlZ7dq1U0pKiiTpwIEDztCRpIiICC1dulQZGRlq27atZsyYoTfffLPCv+MGAACYr8b8npvqUlBQoICAAOXn5/NRcAAAaonz+fu7Vt1zAwAAcC7EDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMYvw/nFndns/Y5u4lwM3GdGvh7iUAwCWNMzcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKPUcfcCAFSt5zO2uXsJcLMx3Vq4ewmAW3HmBgAAGIW4AQAARiFuAACAUYgbAABgFOIGAAAYhbgBAABGIW4AAIBRiBsAAGAU4gYAABiFuAEAAEYhbgAAgFGIGwAAYBTiBgAAGIW4AQAARiFuAACAUYgbAABgFOIGAAAYhbgBAABGIW4AAIBRiBsAAGAU4gYAABiFuAEAAEYhbgAAgFGIGwAAYBTiBgAAGIW4AQAARiFuAACAUYgbAABgFOIGAAAYhbgBAABGIW4AAIBRiBsAAGAU4gYAABiFuAEAAEYhbgAAgFGIGwAAYBTiBgAAGMXtcTNr1iyFh4fLx8dHnTp10vr16886f+bMmbrmmmvk6+ursLAwjRkzRidOnKim1QIAgJrOrXGzcOFCJScnKzU1VRs3blTbtm2VkJCgvLy8Mue///77evLJJ5Wamqoff/xRb731lhYuXKinnnqqmlcOAABqKrfGTXp6uu677z4lJSUpMjJSs2fPlp+fn+bMmVPm/DVr1ujGG2/UXXfdpfDwcHXv3l2DBg0659keAABw6XBb3BQXFys7O1vx8fH/XYyHh+Lj47V27doyt7nhhhuUnZ3tjJldu3Zp2bJluuWWW8o9zsmTJ1VQUODyAAAA5qrjrgMfOnRIJSUlCg4OdhkPDg7WTz/9VOY2d911lw4dOqSbbrpJlmXpjz/+0IgRI856WSotLU2TJk2q0rUDAICay+03FJ+PrKwsTZ06Va+88oo2btyojz76SEuXLtWUKVPK3Wbs2LHKz893Pvbt21eNKwYAANXNbWduAgMD5enpqdzcXJfx3NxchYSElLnNhAkTNHjwYA0fPlyS1Lp1axUVFen+++/XuHHj5OFRutXsdrvsdnvVvwAAAFAjue3Mjbe3t6Kjo5WZmekcczgcyszMVExMTJnbHD9+vFTAeHp6SpIsy7p4iwUAALWG287cSFJycrKGDBmiDh06qGPHjpo5c6aKioqUlJQkSUpMTFRoaKjS0tIkSX369FF6erratWunTp06aceOHZowYYL69OnjjBwAAHBpc2vcDBw4UAcPHlRKSopycnIUFRWl5cuXO28y3rt3r8uZmvHjx8tms2n8+PH69ddfFRQUpD59+ujpp59210sAAAA1jM26xK7nFBQUKCAgQPn5+fL396/y/T+fsa3K94naZUy3Fm49Pu9BuPs9CFwM5/P3d636tBQAAMC5EDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoddy9AACAWZ7P2ObuJcDNxnRr4dbjc+YGAAAYhbgBAABGIW4AAIBRiBsAAGAU4gYAABiFuAEAAEYhbgAAgFGIGwAAYBTiBgAAGIW4AQAARiFuAACAUYgbAABgFOIGAAAYhbgBAABGIW4AAIBRiBsAAGAU4gYAABiFuAEAAEYhbgAAgFGIGwAAYBTiBgAAGIW4AQAARiFuAACAUdweN7NmzVJ4eLh8fHzUqVMnrV+//qzzjx49qpEjR6px48ay2+1q0aKFli1bVk2rBQAANV0ddx584cKFSk5O1uzZs9WpUyfNnDlTCQkJ+vnnn9WoUaNS84uLi9WtWzc1atRIixcvVmhoqH755RfVr1/fDasHAAA1kVvjJj09Xffdd5+SkpIkSbNnz9bSpUs1Z84cPfnkk6Xmz5kzR4cPH9aaNWvk5eUlSQoPD6/OJQMAgBrObZeliouLlZ2drfj4+P8uxsND8fHxWrt2bZnbfPLJJ4qJidHIkSMVHBysVq1aaerUqSopKSn3OCdPnlRBQYHLAwAAmMttcXPo0CGVlJQoODjYZTw4OFg5OTllbrNr1y4tXrxYJSUlWrZsmSZMmKAZM2bof/7nf8o9TlpamgICApyPsLCwKn0dAACgZnH7DcXnw+FwqFGjRnr99dcVHR2tgQMHaty4cZo9e3a524wdO1b5+fnOx759+6pxxQAAoLq57Z6bwMBAeXp6Kjc312U8NzdXISEhZW7TuHFjeXl5ydPT0znWsmVL5eTkqLi4WN7e3qW2sdvtstvtVbt4AABQY7ntzI23t7eio6OVmZnpHHM4HMrMzFRMTEyZ29x4443asWOHHA6Hc2zbtm1q3LhxmWEDAAAuPW69LJWcnKw33nhDb7/9tn788Uc9+OCDKioqcn56KjExUWPHjnXOf/DBB3X48GGNHj1a27Zt09KlSzV16lSNHDnSXS8BAADUMG79KPjAgQN18OBBpaSkKCcnR1FRUVq+fLnzJuO9e/fKw+O//RUWFqbPP/9cY8aMUZs2bRQaGqrRo0friSeecNdLAAAANYxb40aSRo0apVGjRpX5XFZWVqmxmJgYrVu37iKvCgAA1Fa16tNSAAAA50LcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADBKpeLmtttu0zPPPFNqfPr06brjjjsueFEAAACVVam4WbVqlW655ZZS4z179tSqVasueFEAAACVVam4OXbsmLy9vUuNe3l5qaCg4IIXBQAAUFmVipvWrVtr4cKFpcYXLFigyMjIC14UAABAZdWpzEYTJkxQ//79tXPnTv3lL3+RJGVmZuof//iHFi1aVKULBAAAOB+Vips+ffpoyZIlmjp1qhYvXixfX1+1adNGK1asUFxcXFWvEQAAoMIqFTeS1KtXL/Xq1asq1wIAAHDBKnXPzTfffKOvv/661PjXX3+tDRs2XPCiAAAAKqtScTNy5Ejt27ev1Pivv/6qkSNHXvCiAAAAKqtScbN161a1b9++1Hi7du20devWC14UAABAZVUqbux2u3Jzc0uNHzhwQHXqVPo2HgAAgAtWqbjp3r27xo4dq/z8fOfY0aNH9dRTT6lbt25VtjgAAIDzVanTLM8995w6d+6sK6+8Uu3atZMkbd68WcHBwXr33XerdIEAAADno1JxExoaqm+//Vbz58/Xli1b5Ovrq6SkJA0aNEheXl5VvUYAAIAKq/QNMpdddpluuukmNW3aVMXFxZKkzz77TJL017/+tWpWBwAAcJ4qFTe7du1Sv3799N1338lms8myLNlsNufzJSUlVbZAAACA81GpG4pHjx6tiIgI5eXlyc/PT99//71WrlypDh06KCsrq4qXCAAAUHGVOnOzdu1affHFFwoMDJSHh4c8PT110003KS0tTQ8//LA2bdpU1esEAACokEqduSkpKVG9evUkSYGBgdq/f78k6corr9TPP/9cdasDAAA4T5U6c9OqVStt2bJFERER6tSpk6ZPny5vb2+9/vrruuqqq6p6jQAAABVWqbgZP368ioqKJEmTJ09W7969FRsbq8svv1wLFy6s0gUCAACcj0rFTUJCgvO/r776av300086fPiwGjRo4PKpKQAAgOpWZf8QVMOGDatqVwAAAJVWqRuKAQAAairiBgAAGIW4AQAARiFuAACAUYgbAABgFOIGAAAYhbgBAABGIW4AAIBRiBsAAGAU4gYAABiFuAEAAEYhbgAAgFGIGwAAYBTiBgAAGIW4AQAARiFuAACAUYgbAABgFOIGAAAYhbgBAABGIW4AAIBRakTczJo1S+Hh4fLx8VGnTp20fv36Cm23YMEC2Ww29e3b9yKvEAAA1BZuj5uFCxcqOTlZqamp2rhxo9q2bauEhATl5eWddbs9e/bo0UcfVWxsbDWtFAAA1AZuj5v09HTdd999SkpKUmRkpGbPni0/Pz/NmTOn3G1KSkp09913a9KkSbrqqqvOuv+TJ0+qoKDA5QEAAMzl1rgpLi5Wdna24uPjnWMeHh6Kj4/X2rVry91u8uTJatSokYYNG3bOY6SlpSkgIMD5CAsLq5K1AwCAmsmtcXPo0CGVlJQoODjYZTw4OFg5OTllbvPll1/qrbfe0htvvFGhY4wdO1b5+fnOx759+y543QAAoOaq4+4FnI/CwkINHjxYb7zxhgIDAyu0jd1ul91uv8grAwAANYVb4yYwMFCenp7Kzc11Gc/NzVVISEip+Tt37tSePXvUp08f55jD4ZAk1alTRz///LOaNWt2cRcNAABqNLdelvL29lZ0dLQyMzOdYw6HQ5mZmYqJiSk1/9prr9V3332nzZs3Ox9//etf1bVrV23evJn7aQAAgPsvSyUnJ2vIkCHq0KGDOnbsqJkzZ6qoqEhJSUmSpMTERIWGhiotLU0+Pj5q1aqVy/b169eXpFLjAADg0uT2uBk4cKAOHjyolJQU5eTkKCoqSsuXL3feZLx37155eLj9E+sAAKCWcHvcSNKoUaM0atSoMp/Lyso667bz5s2r+gUBAIBai1MiAADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwSo2Im1mzZik8PFw+Pj7q1KmT1q9fX+7cN954Q7GxsWrQoIEaNGig+Pj4s84HAACXFrfHzcKFC5WcnKzU1FRt3LhRbdu2VUJCgvLy8sqcn5WVpUGDBulf//qX1q5dq7CwMHXv3l2//vprNa8cAADURG6Pm/T0dN13331KSkpSZGSkZs+eLT8/P82ZM6fM+fPnz9dDDz2kqKgoXXvttXrzzTflcDiUmZlZzSsHAAA1kVvjpri4WNnZ2YqPj3eOeXh4KD4+XmvXrq3QPo4fP65Tp06pYcOGZT5/8uRJFRQUuDwAAIC53Bo3hw4dUklJiYKDg13Gg4ODlZOTU6F9PPHEE2rSpIlLIP1ZWlqaAgICnI+wsLALXjcAAKi53H5Z6kJMmzZNCxYs0McffywfH58y54wdO1b5+fnOx759+6p5lQAAoDrVcefBAwMD5enpqdzcXJfx3NxchYSEnHXb5557TtOmTdOKFSvUpk2bcufZ7XbZ7fYqWS8AAKj53HrmxtvbW9HR0S43A5++OTgmJqbc7aZPn64pU6Zo+fLl6tChQ3UsFQAA1BJuPXMjScnJyRoyZIg6dOigjh07aubMmSoqKlJSUpIkKTExUaGhoUpLS5MkPfPMM0pJSdH777+v8PBw5705devWVd26dd32OgAAQM3g9rgZOHCgDh48qJSUFOXk5CgqKkrLly933mS8d+9eeXj89wTTq6++quLiYt1+++0u+0lNTdXEiROrc+kAAKAGcnvcSNKoUaM0atSoMp/Lyspy+XrPnj0Xf0EAAKDWqtWflgIAADgTcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwX1+9wAAAzhSURBVAAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxSI+Jm1qxZCg8Pl4+Pjzp16qT169efdf6iRYt07bXXysfHR61bt9ayZcuqaaUAAKCmc3vcLFy4UMnJyUpNTdXGjRvVtm1bJSQkKC8vr8z5a9as0aBBgzRs2DBt2rRJffv2Vd++ffX9999X88oBAEBN5Pa4SU9P13333aekpCRFRkZq9uzZ8vPz05w5c8qc/8ILL6hHjx567LHH1LJlS02ZMkXt27fXyy+/XM0rBwAANVEddx68uLhY2dnZGjt2rHPMw8ND8fHxWrt2bZnbrF27VsnJyS5jCQkJWrJkSZnzT548qZMnTzq/zs/PlyQVFBRc6PLLdKLo2EXZL2qPi/Xeqijeg+A9CHe7GO/B0/u0LOucc90aN4cOHVJJSYmCg4NdxoODg/XTTz+VuU1OTk6Z83Nycsqcn5aWpkmTJpUaDwsLq+SqgbN7yt0LwCWP9yDc7WK+BwsLCxUQEHDWOW6Nm+owduxYlzM9DodDhw8f1uWXXy6bzebGlZmnoKBAYWFh2rdvn/z9/d29HFyCeA/C3XgPXjyWZamwsFBNmjQ551y3xk1gYKA8PT2Vm5vrMp6bm6uQkJAytwkJCTmv+Xa7XXa73WWsfv36F7BqnIu/vz9/qOFWvAfhbrwHL45znbE5za03FHt7eys6OlqZmZnOMYfDoczMTMXExJS5TUxMjMt8ScrIyCh3PgAAuLS4/bJUcnKyhgwZog4dOqhjx46aOXOmioqKlJSUJElKTExUaGio0tLSJEmjR49WXFycZsyYoV69emnBggXasGGDXn/9dXe+DAAAUEO4PW4GDhyogwcPKiUlRTk5OYqKitLy5cudNw3v3btXHh7/PcF0ww036P3339f48eP11FNPqXnz5lqyZIlatWrlrpeA/89utys1NbXUZUCguvAehLvxHqwZbFZFPlMFAABQS7j9l/gBAABUJeIGAAAYhbgBAABGIW4AAIBRiBtUWJcuXfTII4+U+/yePXtks9m0efPmalwVLoZz/awB/Ne8efP45bA1jNs/Co7a46OPPpKXl1e5z4eFhenAgQMKDAysxlXhUrFnzx5FRERo06ZNioqKcvdyAKeBAwfqlltucfcy8CfEDSqsYcOG5T5XXFwsb2/vcv8ZDJjt9M8fF47vZe3j6+srX19fdy8Df8JlKVTYny9VhIeHa8qUKUpMTJS/v7/uv//+Upeljhw5orvvvltBQUHy9fVV8+bNNXfuXHe+BJyHP/74Q6NGjVJAQIACAwM1YcIEnf61WGX9/CXpyy+/VGxsrHx9fRUWFqaHH35YRUVFzn2+++676tChg+rVq6eQkBDdddddysvLcz5/tvdMRESEJKldu3ay2Wzq0qVLhV7HnDlzdN1118lut6tx48YaNWqU87n09HS1bt1al112mcLCwvTQQw/p2LFjzudPX274/PPP1bJlS9WtW1c9evTQgQMHKnyMo0ePavjw4QoKCpK/v7/+8pe/aMuWLc7nJ06cqKioKL355puKiIiQj49PhV4XLq5PP/1U9evXV0lJiSRp8+bNstlsevLJJ51zhg8frnvuuafUZanTP9N3331X4eHhCggI0J133qnCwkLnHIfDobS0NEVERMjX11dt27bV4sWLq+8FGo64QaU999xzatu2rTZt2qQJEyaUen7ChAnaunWrPvvsM/3444969dVXuWRVi7z99tuqU6eO1q9frxdeeEHp6el68803nc+f+fPfuXOnevToodtuu03ffvutFi5cqC+//NLlL/pTp05pypQp2rJli5YsWaI9e/bo3nvvdT5/tvfM+vXrJUkrVqzQgQMH9NFHH53zNbz66qsaOXKk7r//fn333Xf65JNPdPXVVzuf9/Dw0IsvvqgffvhBb7/9tr744gs9/vjjLvs4fvy4nnvuOb377rtatWqV9u7dq0cffbTCx7jjjjuUl5enzz77TNnZ2Wrfvr1uvvlmHT582Dlnx44d+vDDD/XRRx9xz1oNERsbq8LCQm3atEmStHLlSgUGBiorK8s5Z+XKleVG9s6dO7VkyRJ9+umn+vTTT7Vy5UpNmzbN+XxaWpreeecdzZ49Wz/88IPGjBmje+65RytXrryYL+vSYQEVFBcXZ40ePdqyLMu68sorrb59+7o8v3v3bkuStWnTJsuyLKtPnz5WUlJSta8TFy4uLs5q2bKl5XA4nGNPPPGE1bJlS8uyyv75Dxs2zLr//vtdxlavXm15eHhYv//+e5nH+eabbyxJVmFhoWVZZ3/PnPn+qogmTZpY48aNq/D8RYsWWZdffrnz67lz51qSrB07djjHZs2aZQUHB1foGKtXr7b8/f2tEydOuIw3a9bMeu211yzLsqzU1FTLy8vLysvLq/A6UT3at29vPfvss5ZlWVbfvn2tp59+2vL29rYKCwutf//735Yka9u2bdbcuXOtgIAA53apqamWn5+fVVBQ4Bx77LHHrE6dOlmWZVknTpyw/Pz8rDVr1rgcb9iwYdagQYOq4ZWZjzM3qLQOHTqc9fkHH3xQCxYsUFRUlB5//HGtWbOmmlaGqnD99dfLZrM5v46JidH27dudp+nP/Plv2bJF8+bNU926dZ2PhIQEORwO7d69W5KUnZ2tPn36qGnTpqpXr57i4uIk/effkJOq9j2Tl5en/fv36+abby53zooVK3TzzTcrNDRU9erV0+DBg/Xbb7/p+PHjzjl+fn5q1qyZ8+vGjRs7L6Wd6xhbtmzRsWPHdPnll7t8X3bv3q2dO3c651155ZUKCgqq9GvFxREXF6esrCxZlqXVq1erf//+atmypb788kutXLlSTZo0UfPmzcvcNjw8XPXq1XN+/ef3zY4dO3T8+HF169bN5X3xzjvvuLwvUHncUIxKu+yyy876fM+ePfXLL79o2bJlysjI0M0336yRI0fqueeeq6YV4mI68+d/7NgxPfDAA3r44YdLzW3atKmKioqUkJCghIQEzZ8/X0FBQdq7d68SEhJUXFwsqWrfM+e6wXPPnj3q3bu3HnzwQT399NNq2LChvvzySw0bNkzFxcXy8/OTpFKfELTZbM57j851jGPHjqlx48YulzJO+/M9Guf6swT36NKli+bMmaMtW7bIy8tL1157rbp06aKsrCwdOXLEGedlKet943A4JMl5X9fSpUsVGhrqMo9/cLNqEDe4qIKCgjRkyBANGTJEsbGxeuyxx4ibWuLrr792+XrdunVq3ry5PD09y5zfvn17bd261eV+kz/77rvv9Ntvv2natGkKCwuTJG3YsKHUvPLeM6c/QXT6zNG51KtXT+Hh4crMzFTXrl1LPZ+dnS2Hw6EZM2bIw+M/J7E/+OCDCu27osdo3769cnJyVKdOHYWHh5/XvuF+p++7ef75550h06VLF02bNk1HjhzR3//+90rtNzIyUna7XXv37j1rIKHyiBtcNCkpKYqOjtZ1112nkydP6tNPP1XLli3dvSxU0N69e5WcnKwHHnhAGzdu1EsvvaQZM2aUO/+JJ57Q9ddfr1GjRmn48OG67LLLtHXrVmVkZOjll19W06ZN5e3trZdeekkjRozQ999/rylTprjs42zvmUaNGsnX11fLly/XFVdcIR8fHwUEBJz1NUycOFEjRoxQo0aN1LNnTxUWFuqrr77S3/72N1199dU6deqUXnrpJfXp00dfffWVZs+efd7fp7MdIz4+XjExMerbt6+mT5+uFi1aaP/+/Vq6dKn69et3zku7cK8GDRqoTZs2mj9/vl5++WVJUufOnTVgwACdOnWq0mFSr149PfrooxozZowcDoduuukm5efn66uvvpK/v7+GDBlSlS/jksQ9N7hovL29NXbsWLVp00adO3eWp6enFixY4O5loYISExP1+++/q2PHjho5cqRGjx7t/Mh3Wdq0aaOVK1dq27Ztio2NVbt27ZSSkqImTZpI+s8ZmXnz5mnRokWKjIzUtGnTSp3FO9t7pk6dOnrxxRf12muvqUmTJrr11lvP+RqGDBmimTNn6pVXXtF1112n3r17a/v27ZKktm3bKj09Xc8884xatWql+fPnKy0t7by/T2c7hs1m07Jly9S5c2clJSWpRYsWuvPOO/XLL78oODj4vI+F6hcXF6eSkhLnp6IaNmyoyMhIhYSE6Jprrqn0fqdMmaIJEyYoLS1NLVu2VI8ePbR06VLnrzzAhbFZpy8eAwAAGIAzNwAAwCjEDYBa688foz3zsXr1ancvD4CbcFkKQK21Y8eOcp8LDQ3l3/sBLlHEDQAAMAqXpQAAgFGIGwAAYBTiBgAAGIW4AQAARiFuAACAUYgbAABgFOIGAAAY5f8BI8fKU8Jbb68AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "objects = ('iris', 'breast_cancer', 'wine')\n",
    "y_pos = np.arange(len(objects))\n",
    "acc = [accs[0], accs[1], accs[2]]\n",
    "\n",
    "plt.bar(y_pos, acc, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('acc')\n",
    "plt.title('Test accurancy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
